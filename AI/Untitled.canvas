{
	"nodes":[
		{"id":"1c7c555c5223062c","type":"text","text":"my_list = [1, 2, 3, 4, 5]\n1 .append(6)\n2 .remove(3)\n3 len(my_list))\n4 .insert(0, 0)\n5 .extend([8, 9])\n6 del my_list[6]\n7 .sort()\n8 .reverse()\n9 sum(my_list))\n10 min(my_list))\n11 max(my_list))\n12 9 in my_list\n13 my_list[2:4]\n","x":-560,"y":-81,"width":320,"height":421,"color":"4"},
		{"id":"ac07ff9c1b72fe8e","type":"text","text":"my_tuple = (1, 2, 3, 4, 5)\n  1. my_tuple += (6,  7)\n2. len(my_tuple)\n```py\n# Nested tuples and accessing elements\nx = (1, (\"Quadeer\", \"ash\"))\nprint('Accessing nested tuple element:', x[1][1])\nprint('Accessing element in tuple:', x[0])```\n         ","x":-200,"y":-81,"width":616,"height":302,"color":"5"},
		{"id":"4100ee26eb9d1b11","type":"text","text":"# DS","x":-80,"y":-360,"width":250,"height":50,"color":"2"},
		{"id":"8c99c25ae72163c0","type":"text","text":"my_dict = {'a': 1, 'b': 2, 'c': 3}\n1. my_dict = {'a': 1, 'b': 2, 'c': 3}\n2. del my_dict['c']\n3. my_dict['d'] = 4\n4. len(my_dict)\n5. {my_dict.keys()}\n6. {my_dict.values()}","x":460,"y":-81,"width":380,"height":281,"color":"6"},
		{"id":"fc5d71368d1f5aaf","type":"text","text":"1. my_set = {1, 2, 3, 4, 5}\n2. my_set.add(6)\n3. my_set.remove(3)\n4. {len(my_set)}\n```py\n# Intersection of sets\ns1 = {'India', 'America', 'Mecca'}\ns2 = {'USA', 'UK', 'India'}\ns3 = s1 & s2  # or s3 = s1.intersection(s2)\nprint('Intersection of sets s1 and s2:', s3)\n```","x":880,"y":-81,"width":520,"height":361,"color":"4"},
		{"id":"85e30cf27a3bf66e","type":"text","text":"# TRAVERSE","x":-325,"y":400,"width":250,"height":60,"color":"2"},
		{"id":"e3331f766131f872","type":"text","text":"```PY\ndef dfs(graph, initial):\n    visited = []\n    stack = [initial]\n    \n    while stack:\n        node = stack.pop()\n        if node not in visited:\n            visited.append(node)\n            neighbours = graph[node]\n\n            for k in neighbours:\n                stack.append(k)\n                \n    return visited\n\nprint(dfs(graph, '5'))\n\n```","x":-160,"y":580,"width":526,"height":500,"color":"6"},
		{"id":"20b1efb3960b2ae1","type":"text","text":"```PY\ndef bfs(graph, initial):\n    visited = []\n    queue = [initial]\n\n    while queue:\n        node = queue.pop(0)\n        if node not in visited:\n            visited.append(node)\n            neighbours = graph[node]\n            for k in neighbours:\n                queue.append(k)\n    return visited\n\nprint(bfs(graph, '5'))\n```","x":-658,"y":580,"width":458,"height":420,"color":"5"},
		{"id":"8355d770e2f3bdce","type":"text","text":"# MISC","x":-477,"y":1047,"width":250,"height":80,"color":"3"},
		{"id":"65d2693a088a13d0","type":"text","text":" ```PY\nfrom queue import PriorityQueue\n\nv = 14\ngraph = [[] for i in range(v)]\n\ndef best_first_search(actual_src, target, n):\n    visited = [False] * n\n    pq = PriorityQueue()\n    pq.put((0, actual_src))\n    visited[actual_src] = True\n    \n    while not pq.empty():\n        u = pq.get()[1]\n        print(u, end=\" \")\n        \n        if u == target:\n            break\n        \n        for v, c in graph[u]:\n            if not visited[v]:\n                visited[v] = True\n                pq.put((c, v))\n        \n        print()\n\ndef addedge(x, y, cost):\n    graph[x].append((y, cost))\n    graph[y].append((x, cost))\n\naddedge(0, 1, 3)\naddedge(0, 2, 6)\naddedge(0, 3, 5)\naddedge(1, 4, 9)\naddedge(1, 5, 8)\naddedge(2, 6, 12)\naddedge(2, 7, 14)\naddedge(3, 8, 7)\naddedge(8, 9, 5)\naddedge(8, 10, 6)\naddedge(9, 11, 1)\naddedge(9, 12, 10)\naddedge(9, 13, 2)\n\nsource = 0\ntarget = 9\nbest_first_search(source, target, v)\n```","x":-257,"y":1267,"width":758,"height":1173,"color":"6"},
		{"id":"6926deaab84295f6","type":"text","text":"```py\ndef aStarAlgo(start_node, stop_node):\n    open_set = {start_node}\n    closed_set = set()\n    g = {}\n    parents = {}\n    g[start_node] = 0\n    parents[start_node] = start_node\n\n    while len(open_set) > 0:\n        n = None\n        for v in open_set:\n            if n is None or g[v] + heuristic(v) < g[n] + heuristic(n):\n                n = v\n\n        if n == stop_node or Graph_nodes[n] is None:\n            pass\n        else:\n            for (m, weight) in get_neighbors(n):\n                if m not in open_set and m not in closed_set:\n                    open_set.add(m)\n                    parents[m] = n\n                    g[m] = g[n] + weight\n                else:\n                    if g[m] > g[n] + weight:\n                        g[m] = g[n] + weight\n                        parents[m] = n\n                        if m in closed_set:\n                            closed_set.remove(m)\n                            open_set.add(m)\n\n        if n is None:\n            print('Path does not exist!')\n            return None\n\n        if n == stop_node:\n            path = []\n            while parents[n] != n:\n                path.append(n)\n                n = parents[n]\n            path.append(start_node)\n            path.reverse()\n            print('Path found: {}'.format(path))\n            return path\n\n        open_set.remove(n)\n        closed_set.add(n)\n    print('Path does not exist!')\n    return None\n\n\ndef get_neighbors(v):\n    if v in Graph_nodes:\n        return Graph_nodes[v]\n    else:\n        return None\n\n\ndef heuristic(n):\n    H_dist = {\n        'A': 10,\n        'B': 40,\n        'C': 30,\n        'D': 50,\n    }\n    return H_dist[n]\n\n\nGraph_nodes = {\n    'A': [('B', 10), ('C', 20)],\n    'B': [('A', 10), ('D', 3)],\n    'C': [('A', 20), ('D', 50)],\n    'D': [('B', 2), ('C', 10)],\n}\n\naStarAlgo('A', 'D')\n\n```","x":-1137,"y":1267,"width":762,"height":1893,"color":"3"},
		{"id":"d5d3ec8caf48e9af","type":"text","text":"# NLTK","x":915,"y":340,"width":250,"height":60,"color":"3"},
		{"id":"7a147689d7f7e440","type":"text","text":"# DECISION TREE","x":20,"y":2520,"width":358,"height":80,"color":"4"},
		{"id":"3133ebbb274a07e0","type":"text","text":"```py\nfrom nltk.stem import WordNetLemmatizer\n\n# Create a WordNetLemmatizer object\nlemmatizer = WordNetLemmatizer()\n\n# Perform lemmatization on various words\nprint(lemmatizer.lemmatize(\"plays\", 'v'))\nprint(lemmatizer.lemmatize(\"played\", 'v'))\nprint(lemmatizer.lemmatize(\"play\", 'v'))\nprint(lemmatizer.lemmatize(\"playing\", 'v'))\n```","x":458,"y":898,"width":490,"height":356,"color":"1"},
		{"id":"3a8cb9d10d49f4b5","type":"text","text":"# Neural Network\n```py\nimport numpy as np\nfrom sklearn.datasets import load_digits\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.metrics import accuracy_score, confusion_matrix\n\n# Load the digits dataset\ndataset = load_digits()\n\n# Split the dataset into training and testing sets\nx_train, x_test, y_train, y_test = train_test_split(dataset.data, dataset.target, test_size=0.2)\n\n# Create and train the MLPClassifier\nNN = MLPClassifier(hidden_layer_sizes=(10), max_iter=1000)\nNN.fit(x_train, y_train)\n\n# Make predictions on the test set\ny_pred = NN.predict(x_test)\n\n# Calculate the accuracy of the model\nscore = accuracy_score(y_test, y_pred) * 100\nprint('Accuracy for neural network is:', score)\n\n# Visualize one of the digits\nimport matplotlib.pyplot as plt\nplt.gray()\nplt.matshow(dataset.images[1730])\nplt.show()\n\n# Print the corresponding data for the digit\nprint(dataset.data[1730])\n\n```","x":680,"y":1473,"width":1000,"height":927,"color":"3"},
		{"id":"6b4d759ce0575d8d","type":"text","text":"# neural Network","x":915,"y":1350,"width":295,"height":93,"color":"4"},
		{"id":"49d2695bb23938b1","type":"text","text":"```py\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\n\n# Example sentence\nexample_sent = \"This is a sample sentence showing off the stop words filtration.\"\n\n# Get the set of English stopwords\nstop_words = set(stopwords.words('english'))\n\n# Tokenize the example sentence\nword_tokens = word_tokenize(example_sent)\n\n# Filter out stopwords using list comprehension with lowercase conversion\nfiltered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\n\n# Filter out stopwords without lowercase conversion\nfiltered_sentence = []\nfor w in word_tokens:\n    if w not in stop_words:\n        filtered_sentence.append(w)\n\n# Print the original tokens and filtered sentence\nprint(\"Original Tokens:\", word_tokens)\nprint(\"Filtered Sentence:\", filtered_sentence)\n\n```","x":986,"y":570,"width":828,"height":731,"color":"4"},
		{"id":"a5ddc65091e5fcdd","type":"text","text":"```py\n\n# Import necessary modules\nfrom nltk import word_tokenize, pos_tag\n\n# Define the text\ntext = 'geeksforgeeks is a great learning platform'\n\n# Tokenize the text\ntokenized_text = word_tokenize(text)\n\n# Perform Part-of-Speech (POS) tagging\ntags = pos_tag(tokenized_text)\n\n# Print the tags\nprint(tags)\n\n```","x":1880,"y":570,"width":620,"height":487,"color":"5"},
		{"id":"5a274b78cf06869a","type":"text","text":"``` PY\n# Import PorterStemmer from nltk.stem\nfrom nltk.stem import PorterStemmer\n\n# Create a PorterStemmer object\nporter = PorterStemmer()\n\n# Perform stemming on various words\nprint(porter.stem(\"play\"))\nprint(porter.stem(\"plays\"))\nprint(porter.stem(\"playing\"))\nprint(porter.stem(\"played\"))\n\n```","x":458,"y":570,"width":490,"height":328,"color":"1"},
		{"id":"acc879412b52bd33","type":"text","text":"```prolog\n% Facts\nfemale(pam).\nfemale(liz).\nfemale(pat).\nfemale(ann).\nmale(jim).\nmale(bob).\nmale(tom).\nmale(peter).\nparent(pam, bob).\nparent(tom, bob).\nparent(tom, liz).\nparent(bob, ann).\nparent(bob, pat).\nparent(pat, jim).\nparent(bob, peter).\nparent(peter, jim).\n\n% Rules\nmother(X, Y):- parent(X, Y), female(X).\nfather(X, Y):- parent(X, Y), male(X).\nhaschild(X):- parent(X, _).\nsister(X, Y):- parent(Z, X), parent(Z, Y), female(X), X \\== Y.\nbrother(X, Y):- parent(Z, X), parent(Z, Y), male(X), X \\== Y.\n\n```","x":1760,"y":1512,"width":760,"height":683,"color":"6"},
		{"id":"5d7a0ef6caf9fd1f","type":"text","text":"# FAMILY","x":2015,"y":1443,"width":250,"height":50,"color":"4"},
		{"id":"21db69226a448b75","type":"text","text":"```PY\n# Define the dataset\ndataset = np.array([\n    ['famous engg works', 11155, 155000],\n    ['asset flip', 11134, 33100],\n    ['bmw', 555, 10340],\n    ['mjcet', 1332, 10400],\n    ['tax', 1141, 12000],\n    ['jeee', 1411, 10040],\n    ['yoyo', 111, 10200],\n    [' flip', 1141, 1000],\n    ['nessain', 1161, 10400],\n    ['asset', 1611, 10040]\n])\n\n# Print the dataset\nprint(dataset)\n\n# Extract features (x) and target (y) variables\nx = dataset[:, 1:2].astype(int)\ny = dataset[:, 2].astype(int)\n\n# Create a DecisionTreeRegressor model\nregressor = DecisionTreeRegressor(random_state=0)\n\n# Fit the model to the data\nregressor.fit(x, y)\n\n# Predict the profit for a given cost\ny_pred = regressor.predict([[111]])\nprint(y_pred)\n\n# Generate a range of values for plotting\nx_grid = np.arange(min(x), max(x), 0.01)\nx_grid = x_grid.reshape((len(x_grid), 1))\n\n# Plot the data and the regression line\nplt.scatter(x, y, color='red')\nplt.plot(x_grid, regressor.predict(x_grid), color='blue')\nplt.title('Business Analytics')\nplt.xlabel('Cost')\nplt.ylabel('Profit')\nplt.show()\n\n```","x":-120,"y":2660,"width":640,"height":1100,"color":"4"},
		{"id":"87c18f818adad084","x":1040,"y":2540,"width":250,"height":60,"type":"text","text":"# SIMPLE"},
		{"id":"12ab8173b6a1f4ed","x":926,"y":2660,"width":474,"height":380,"color":"3","type":"text","text":"```prolog\nfather_of(joe, paul).\nfather_of(joe, mary).\nmother_of(jane, paul).\nmother_of(jane, mary).\nmale(paul).\nmale(joe).\nfemale(mary).\nfemale(jane).\n```"}
	],
	"edges":[
		{"id":"3db099bf757f7abe","fromNode":"4100ee26eb9d1b11","fromSide":"bottom","toNode":"1c7c555c5223062c","toSide":"top","color":"6","label":"List"},
		{"id":"ce6e4af7ea2e27a9","fromNode":"4100ee26eb9d1b11","fromSide":"bottom","toNode":"ac07ff9c1b72fe8e","toSide":"top","color":"1","label":"Tuple"},
		{"id":"c9343593666b0480","fromNode":"4100ee26eb9d1b11","fromSide":"bottom","toNode":"8c99c25ae72163c0","toSide":"top","color":"3","label":"Dictionary"},
		{"id":"22efb8609e405c6d","fromNode":"4100ee26eb9d1b11","fromSide":"bottom","toNode":"fc5d71368d1f5aaf","toSide":"top","color":"2","label":"SETS"},
		{"id":"e5790eedc74ec09a","fromNode":"85e30cf27a3bf66e","fromSide":"bottom","toNode":"20b1efb3960b2ae1","toSide":"top","color":"1","label":"BFS"},
		{"id":"732c7bcfacd2dae2","fromNode":"85e30cf27a3bf66e","fromSide":"bottom","toNode":"e3331f766131f872","toSide":"top","color":"4","label":"DFS"},
		{"id":"3d9a7f4607603945","fromNode":"8355d770e2f3bdce","fromSide":"bottom","toNode":"6926deaab84295f6","toSide":"top","color":"4","label":"A *"},
		{"id":"6ceb522c298ddd3e","fromNode":"8355d770e2f3bdce","fromSide":"bottom","toNode":"65d2693a088a13d0","toSide":"top","color":"6","label":"Best-fit"},
		{"id":"77225b842bbed0e8","fromNode":"d5d3ec8caf48e9af","fromSide":"bottom","toNode":"5a274b78cf06869a","toSide":"top"},
		{"id":"a83677ed8d181240","fromNode":"d5d3ec8caf48e9af","fromSide":"bottom","toNode":"49d2695bb23938b1","toSide":"top","label":"stop words"},
		{"id":"471260b4d0019a55","fromNode":"5a274b78cf06869a","fromSide":"bottom","toNode":"3133ebbb274a07e0","toSide":"top"},
		{"id":"36033475f939054a","fromNode":"d5d3ec8caf48e9af","fromSide":"bottom","toNode":"a5ddc65091e5fcdd","toSide":"top","label":"POS"},
		{"id":"58b1fe722e00fe74","fromNode":"6b4d759ce0575d8d","fromSide":"bottom","toNode":"3a8cb9d10d49f4b5","toSide":"top"},
		{"id":"1cf7f3595748d7d7","fromNode":"5d7a0ef6caf9fd1f","fromSide":"bottom","toNode":"acc879412b52bd33","toSide":"top"},
		{"id":"b12cf95cfdc77d28","fromNode":"7a147689d7f7e440","fromSide":"bottom","toNode":"21db69226a448b75","toSide":"top"},
		{"id":"8e8583db350d3088","fromNode":"87c18f818adad084","fromSide":"bottom","toNode":"12ab8173b6a1f4ed","toSide":"top"}
	]
}